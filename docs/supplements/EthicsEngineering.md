# Ethics (Engineering Research)

A study in which a novel technological or socio-technical artifact is created and evaluated.

## Application

This standard applies to studies that propose and evaluate technological artifacts, including algorithms, models, languages,
methods, systems, tools, and other computer-based technologies.

## Specific Attributes
### Essential Attributes
- [ ] describes anticipated benefits of the artifact for individuals, communities, organizations or society as a whole
- [ ] describes any burdens created by using the artifact, on whom these burdens fall, whether burderns fall dispropritonately on vulnerable individuals or groups and, if so, attempts to mitigate such burdens
- [ ] describes all plausible, non-trivial potential harms arising from using the artifact (e.g. in terms of privacy (including surveillance and workplace monitoring), security, exclusion, bias, inequality, accessibility, deception, pollution, environmental destructiion and other societal, community, organizational, individual or ecological impacts) and attempts to mitigate such harms
- [ ] considers ways in which the artifact could be abused, misused, hacked, compromised, or otherwise applied to nefarious or unethical purposes, and describes attmpts to mitigate such abuses
- [ ] considers unintended consequences of using the artifact and describes attempts to mitigate them
- [ ] considers unethical or otherwise problematic behaviours that could be encouraged by using or misuing the artifact in the anticipated context of use and describes attempts to mitigate such behaviours
- [ ] describes the environmental impact of the work in terms of carbon emissions (for development and use) and other respects (e.g. materials, mineral mining required)
- [ ] justifies the potential burdens, harms, misuses, unintended consequences and environmental impacts of the artifact in terms of its benefits, considering particularly the relationship between who reaps the benefits and who suffers the burdens, harms, etc. how the latter are mitigated. 

### Desirable Attributes
- [ ] quantifies the carbon emissions generated by (1) developing and (2) using the artifact, especially for machine learning<sup><a class="footnote footnote_ref">1</a></sup>
- [ ] quantify carbon emissions over the whole line of research, not just this part of the work (for artifacts emerging from a line of research) <sup>[1](#myfootnote1)</sup>
- [ ] relates ethics discussion to frameworks of professional practice or the UN Sustainable Development Goals
- [ ] discuss relative harms and benefits when describing alternatives in related work

### Extraordinary Attributes
- [ ] provides complete statement of ethical approval from institutional REC/IRB in relation specifically to the technological artifact (typically as supplementary materials)
- [ ] describes measures taken to reduce the environmental impact of the work such as carbon offsetting

## General Quality Criteria

Assessing the ethicality of a new technology is mainly about (1) the degree to which potential harms are acknowledged and mitigated, and (2) juxtaposing harms and benefits. We do not reject a new technology because of the potential for harm---virtually every technology has costs and potential for harms and misuse. Rather, we reject a paper when it evinces a general lack of awareness or consideration of potential harms, obfuscation of harms, when the harms outweigh the benefits, or when benefits accrue to people who don't really need them (e.g. the rich and powerful) while the costs are borne by different people who cannot afford them (e.g. the poor and vulnerable).  

## Antipatterns

- Justifying an artifact as beneficial solely on its own merits without consideration of the broad impacts of its use
- Justifying an artifact as beneficial solely on the grounds that it is similar to other artifacts that have been useful and without considering the impacts specifically in this case
- Justifying an artifact as beneficial without considering the potential contexts of use, including beyond those targeted
- Failure to identify any misuse or risk scenarios

## Examples of Acceptable Deviations

- Justified inability to quantify machine learning carbon costs<sup>[1](#myfootnote1)</sup>

## Invalid Criticisms

- "The study was not approved by an ethical review board" is not grounds for rejection unless there is a substantive ethical concern relating to the artifact that such a board should have prevented.
- "There exists a potential harm, burden, etc. that the paper did not consider" is not by itself grounds for rejection in a paper that discusses many harms, burdens, etc.; it is normal for reviewers to dream up scenarios that authors have not considered.    

## Suggested Readings

British Computer Society, *Code of Conduct*, [https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf]

Don Gotterbarn, Keith Miller, and Simon Rogerson. 1997. Software engineering code of ethics. *Commun. ACM* 40, 11 (November 1997), 110-118. DOI: 10.1145/265684.265699

Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, and Thomas Dandres.  2019.  Quantifying the Carbon Emissions of Machine Learning.  *NeurIPS2019 at ClimateChangeAI.*  [https://arxiv.org/abs/1910.09700v2]

Michael D. Myers, John R. Venable, 2014. A set of ethical principles for design science research in information systems, *Information & Management*, 51(6), 801-809.  DOI: 10.1016/j.im.2014.01.002.

United Nations. 2015.  *Sustainable Development Goals*. [https://sdgs.un.org/goals]

Caroline Whitbeck. 2011.  *Ethics in Engineering Practice and Research*. Cambridge University Press.  ISBN 978-0521723985.  Chapters 10 and 11 in particular.

---
<sup><a class="footnote footnote_text">1</a></sup> The tool at [https://mlco2.github.io/impact/#home] provides an estimate of the carbon impact of machine learning for a wide variety of hardware running in various cloud platforms including private infrastructure, producing results in a publication-friendly format.
