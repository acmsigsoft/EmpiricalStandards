# Systematic Reviews 
<standard name="Systematic Reviews">


*<desc>A study that appraises, analyses, and synthesizes primary or secondary literature to provide a complete, exhaustive summary of current evidence regarding one or more specific topics or research questions</desc>*



## Application 

-   Applies to studies that systematically find and analyze existing
    literature about a specified topic
-   Applies both to secondary and tertiary studies
-   Does not apply to ad-hoc literature reviews, case surveys or
    advanced qualitative synthesis methods (e.g. meta-ethnography)

## Specific Attributes 

### Essential Attributes 
<checklist name="Essential">

<intro>

- [ ]	identifies type of review (e.g. case survey, critical review, meta-analysis, meta-synthesis, scoping review)

<method>

- [ ]	presents step-by-step, systematic, replicable description of search process including search terms<sup><a class="footnote footnote_ref">1</a></sup>  
- [ ]	defines clear selection criteria
- [ ]	specifies the data extracted from each primary study<sup><a class="footnote footnote_ref">2</a></sup> ; explains relationships to research questions
- [ ]	describes in detail how data were extracted and synthesized (can be qualitative or quantitative)
- [ ]	describes coding scheme(s) and their use

<results>

- [ ]	clear chain of evidence from the extracted data to the answers to the research question(s)

<discussion>

- [ ]	presents conclusions or recommendations for practitioners/non-specialists

<other>		

</checklist>

### Desirable Attributes 
<checklist name="Desirable">
	
- [ ]	provides supplementary materials such as protocol, search terms, search results, selection process results; complete dataset, analysis scripts; coding scheme, examples of coding, decision rules, descriptions of edge cases
- [ ]	mitigates sampling bias and publication bias, using some (not all) of:  
(i) manual and keyword automated searches;   
(ii) backward and forward snowballing searches;  
(iii) checking profiles of prolific authors in the area;   
(iv) searching both formal databases (e.g. ACM Digital Library) and indexes (e.g. Google Scholar);   
(v) searching for relevant dissertations;   
(vi) searching pre-print servers (e.g. arXiv);   
(iiv) soliciting unpublished manuscripts through appropriate listservs or social media;  
(iiiv) contacting known authors in the area. 
- [ ]	demonstrates that the search process is sufficiently rigorous for the systematic review goals<sup><a class="footnote footnote_ref">3</a></sup>  
- [ ]	assesses quality of primary studies using an a priori coding scheme (e.g. relevant empirical standards); explains how quality was assessed; excludes low quality studies (ok) or models study quality as a moderating variable (better) 
- [ ]	assesses coverage (e.g. funnel plots, tweedle trim-and-fill method, percentage of known papers found)
- [ ]	(positivist reviews), uses 2+ independent analysts; analyzes inter-rater reliability (see the [IRR/IRA Supplement](https://github.com/acmsigsoft/EmpiricalStandards/blob/master/docs/supplements/InterRaterReliabilityAndAgreement.md)); explains how discrepancies among coders were resolved<sup><a class="footnote footnote_ref">4</a></sup> 
- [ ]	(interpretivist reviews) reflects on how researcher’s biases may have affected their analysis
- [ ]	consolidates results using tables, diagrams, or charts 
- [ ]   includes a PRISMA flow diagram (cf. Moher et al. 2009)
- [ ]	performs analysis through an existing or new conceptual framework (qualitative synthesis)
- [ ]	uses meta-analysis methods appropriate for primary studies; does not use vote counting 
- [ ]	integrates results into prior theory or research; identifies gaps, biases, or future directions
- [ ]	presents results as practical, evidence-based guidelines for practitioners, researchers, or educators
- [ ]	clearly distinguishes evidence-based results from interpretations and speculation<sup><a class="footnote footnote_ref">5</a></sup>	
</checklist>
     
### Extraordinary Attributes
<checklist name="Extraordinary">

- [ ]	two or more researchers independently undertaking the preliminary search process before finalizing the search scope and search keywords
- [ ]	contacted primary study authors to ensure interpretations are correct, and elicit additional details not found in the papers such as access to raw data
- [ ]	applies integrative data analysis<sup><a class="footnote footnote_ref">6</a></sup>	
	
</checklist>

## Examples of Acceptable Deviations 

-   No attempts to mitigate publication bias in a study explicitly
    examining a specific venue's (e.g. CACM or ICSE) coverage of a given
    topic.
-   Using probability sampling on primary studies when there are too
    many to analyze (i.e. thousands).
-   No recommendations for practitioners in a study of a methodological
    issue (e.g. representative sampling).

## Antipatterns 

-   A laundry-list description of the studies (A found X, B found Y,
    ...), rather than a synthesis of the findings.
-   Relying on characteristics of the publication venues as a proxy for
    the quality of the primary studies instead of assessing primary
    studies' quality explicitly.
-   Reviewing an area in which there are too few high-quality primary
    studies to draw reliable conclusions.
	
## Invalid Criticisms

-   The search queries are not identical in all databases.
-   The analysis strategy should be more qualitative/quantitative
	

## Suggested Readings 

Paul Ralph and Sebastian Baltes. 2022. Paving the Way for Mature Secondary Research: The Seven Types of Literature Review. *Proceedings of The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022) Ideas, Visions and Reflections Track*, Singapore: ACM, Nov. 14–18. 
	
Moher D, Liberati A, Tetzlaff J, Altman DG, The PRISMA Group (2009).
*P*referred *R*eporting *I*tems for *S*ystematic Reviews and
*M*eta-*A*nalyses: The PRISMA Statement. PLoS Med 6, 7: e1000097.
doi:10.1371/journal.pmed1000097

Michael Borenstein and Larry V. Hedges and Julian P.T. Higgins and
Hannah R. Rothstein. 2009. *Introduction to Meta-Analysis.* John Wiley &
Sons Ltd.

Daniela S. Cruzes and Tore Dybå. 2010. Synthesizing evidence in software
engineering research. In Proceedings of the 2010 ACM-IEEE International
Symposium on Empirical Software Engineering and Measurement (ESEM '10).
Association for Computing Machinery, New York, NY, USA, Article 1,
1–10. DOI:10.1145/1852786.1852788

Barbara Kitchenham and Stuart Charters. 2007. Guidelines for performing
Systematic Literature Reviews in Software Engineering.

Matthew B. Miles and A. Michael Huberman and Jonny Saldana. 2014.
Qualitative Data Analysis: A Methods Sourcebook. Sage Publications Inc.

Kai Petersen, Robert Feldt, Shahid Mujtaba, and Michael Mattsson. 2008.
Systematic mapping studies in software engineering. In *12th
International Conference on Evaluation and Assessment in Software
Engineering (EASE).* (Jun. 2008), 1–10.
	
## Exemplars

Jo Hannay, Tore Dybå, Erik Arisholm, and Dag IK Sjøberg. 2009. The effectiveness of pair programming: A meta-analysis. _Information and software technology_ 51,7: 1110-1122.
	
Yahya Rafique, and Vojislav B. Mišić. 2012. The effects of test-driven development on external quality and productivity: A meta-analysis. _IEEE Transactions on Software Engineering_ 39,6: 835-856.
	
Martin Shepperd, David Bowes, and Tracy Hall. (2014) Researcher bias: The use of machine learning in software defect prediction. _IEEE Transactions on Software Engineering_ 40,6: 603-616.

---
<footnote><sup><a class="footnote footnote_text">1</a></sup>Searches can be manual or automated or a combination of both.</footnote><br>
<footnote><sup><a class="footnote footnote_text">2</a></sup>Primary studies are the studies that are being reviewed. In a tertiary study, the “primary studies” are themselves reviews.</footnote><br>
<footnote><sup><a class="footnote footnote_text">3</a></sup>e.g. formal meta-analysis of experiments has higher requirements for completeness than mapping studies of broad topic areas.</footnote><br>
<footnote><sup><a class="footnote footnote_text">4</a></sup>By discussion and agreement, voting, adding tie-breaker, consulting with study authors, etc.</footnote><br>
<footnote><sup><a class="footnote footnote_text">5</a></sup>Simply separating results and discussion into different sections is typically sufficient. No speculation in the results section.</footnote><br>
<footnote><sup><a class="footnote footnote_text">6</a></sup>See https://idaunc.web.unc.edu/home/ida/</footnote><br>
</standard>
