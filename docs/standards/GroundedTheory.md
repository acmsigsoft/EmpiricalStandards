# Grounded Theory

<standard name="Grounded Theory">

*<desc>A study of a specific area of interest or phenomenon that involves
iterative and interleaved rounds of qualitative data collection and
analysis, leading to key patterns (e.g. concepts, categories)</desc>*


## Application 

This standard applies to empirical inquiries that meet all of the
following conditions:

-   Explores a broad area of investigation without specific, up-front
    research questions.
-   Applies theoretical sampling with iterative and interleaved rounds
    of data collection and analysis.
-   Reports rich and nuanced findings, typically including verbatim
    quotes and samples of raw data.

For predominately qualitative inquiries that do not iterate between data
collection and analysis or do not use theoretical sampling, consider the
**Case Study Standard** or the **Qualitative Survey Standard**.

## Specific Attributes 

### Essential Attributes 
<checklist name="Essential">

<intro>


<method>

- [ ]	identifies the variant(s) of Grounded Theory used/adapted (Glaser, Strauss/Corbin, Charmaz, etc.)
- [ ]	explains what initial data was used and what other data was analyzed later and why ("theoretical sampling")
- [ ]	characterizes the data (e.g. participants' demographics, work roles)
- [ ]	declares either that theoretical saturation was achieved (and how this was determined) or that the theory is possibly or likely incomplete
- [ ]	explains how key patterns (e.g. categories) were found via GT steps (e.g. selective coding)
    
<results>

- [ ]	states results in terms of abstract concepts that assign meaning to data ("theoretical coding": do not merely _describe_ the data)
- [ ]	grounds most or all important concepts in raw data explicitly (e.g. by providing quotations)

<discussion>

<other>
     
</checklist>    
    
### Desirable Attributes 
<checklist name="Desirable">
    
- [ ]	results involve relationships between the abstract concepts
- [ ]	a graphic provides an overview of the main concepts and relationships
- [ ]	explains how and why study deviates from claimed GT variant and/or how variants were combined
- [ ]	includes data representing a diverse (rather than homogeneous) spectrum of cases
- [ ]	explains how memo writing was used to drive the work
- [ ]   validates results using member checking, dialogical interviewing, feedback from non-participant practitioners or research audits of coding by advisors or other researchers
- [ ]	characterizes the setting such that readers can assess transferability; discusses transferability
- [ ]	compares results with (or integrates them into) prior theory or related research
- [ ]	reflects on how researcher’s biases may have affected their analysis
- [ ]	explains the role of literature, especially where an extensive review preceded the GT study
- [ ]	provides supplemental materials such as interview guide(s), coding schemes, coding examples, decision rules, or extended chain-of-evidence tables
</checklist>
     
### Extraordinary Attributes 
<checklist name="Extraordinary">

- [ ]	triangulates with extensive quantitative data (e.g. questionnaires, sentiment analysis)
- [ ]	employs a team of researchers and explains their roles 
</checklist>

## Quality Criteria 

Glaser, Strauss, Corbin and Charmaz advance inconsistent quality
criteria. Using definitions in our [Glossary](../glossary), reviewers should
consider common qualitative criteria such as **credibility**,
**resonance**, **usefulness** and the degree to which results *extend*
our cumulative knowledge. Quantitative quality criteria such as internal
validity, construct validity, replicability, generalizability and
reliability typically do not apply.

## Examples of Acceptable Deviations 

-   In a study of sexual harassment at a named organization, detailed
    description of interviewees and direct quotations are omitted to
    protect participants.

## Antipatterns

-   Conducting data collection and data analysis sequentially; applying
    only analysis techniques of GT.
-   Data analysis focusing on counting words, codes, concepts, or
    categories instead of interpreting.
-   Presenting a tutorial on grounded theory instead of explaining how
    the current study was conducted.
-   Small, heterogenous samples creating the illusion of convergence and
    theoretical saturation. For example, it is highly unlikely that a
    full theory can be derived only from interviews with 20 people.
-   Focusing only on interviews without corroborating statements with
    other evidence (e.g. documents, observation).

## Invalid Criticisms

-   Lack of quantitative data; causal analysis; objectivity, internal
    validity, reliability, or generalizability.
-   Lack of replicability or reproducibility; not releasing transcripts
-   Lack of representativeness (e.g. of a study of Turkish programmers,
    'how does this generalize to America?')
-   Research questions should have been different
-   Findings should have been presented as a different set of
    relationships, hypotheses, or a different theory.

## Suggested Readings 

Steve Adolph, Wendy Hall, and Philippe Kruchten. 2011. Using grounded
theory to study the experience of software development. *Empirical
Software Engineering*. 16, 4 (2011), 487–513.
    
Khaldoun M. Aldiabat and Carole-Lynne Le Navenec. "Data Saturation: The Mysterious Step in Grounded Theory Methodology." _The Qualitative Report_, vol. 23, no. 1, 2018, pp. 245-261.    

Kathy Charmaz. 2014. *Constructing grounded theory*. Sage.

Juliet Corbin and Anselm Strauss. 2014. *Basics of qualitative research: Techniques and procedures for developing grounded theory*. Sage publications.

Dennis A. Gioia, Kevin G. Corley, and Aimee L. Hamilton. "Seeking qualitative rigor in inductive research: Notes on the Gioia methodology." _Organizational Research Methods_ 16, no. 1 (2013): 15-31.

Janet Morse Morse, Barbara J. Bowers, Kathy Charmaz, Adele E. Clarke, Juliet Corbin, Caroline Jane Porr, and Phyllis Noerager Stern (eds). (2021) _Developing Grounded Theory: The Second Generation Revisited_. Routledge, New York, USA.

Klaas-Jan Stol, Paul Ralph, and Brian Fitzgerald. 2016. Grounded theory
in software engineering research: a critical review and guidelines. In
*Proceedings of the 38th International Conference on Software
Engineering (ICSE '16)*. Association for Computing Machinery, New York,
NY, USA, 120–131. DOI: 10.1145/2884781.2884833


## Exemplars

Barthélémy Dagenais and Martin P. Robillard. 2010. Creating and evolving
developer documentation: understanding the decisions of open source
contributors. In Proceedings of the eighteenth ACM SIGSOFT international
symposium on Foundations of software engineering (FSE '10). Association
for Computing Machinery, New York, NY, USA, 127–136. DOI:
10.1145/1882291.1882312

Rashina Hoda, James Noble, and Stuart Marshall. 2012. Self-organizing
roles on agile software development teams. *IEEE Transactions on
Software Engineering*. IEEE 39, 3 (May 2012), 422–444. DOI:
10.1109/TSE.2012.30

Todd Sedano, Paul Ralph, and Cécile Péraire. 2017. Software development
waste. In 2017 IEEE/ACM 39th International Conference on Software
Engineering (ICSE). (May. 2017), 130–140. DOI: 10.1109/icse (2017).

Christoph Treude and Margaret-Anne Storey. 2011. Effective communication
of software development knowledge through community portals. In
*Proceedings of the 19th ACM SIGSOFT symposium and the 13th European
conference on Foundations of software engineering (ESEC/FSE '11)*.
Association for Computing Machinery, New York, NY, USA, 91–101.
DOI:10.1145/2025113.2025129

Michael Waterman, James Noble, and George Allan. 2015. How much
up-front? A grounded theory of agile architecture. In *2015 IEEE/ACM
37th IEEE International Conference on Software Engineering*. 1, (May
2015), 347–357.
    
---
<footnote><sup><a class="footnote footnote_text">1</a></sup>cf. Khaldoun M. Aldiabat and Carole-Lynne Le Navenec. "Data Saturation: The Mysterious Step in Grounded Theory Methodology." _The Qualitative Report_, vol. 23, no. 1, 2018, pp. 245-261.</footnote><br>    
</standard>
